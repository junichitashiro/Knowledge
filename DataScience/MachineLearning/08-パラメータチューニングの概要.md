# パラメータチューニングの概要

## パラメータ
* データ分析において設定しておかなければならない値
* モデルが複雑になるほどパラメータ数は増加する傾向にある

## 決定木のパラメータ例
* max_depth
  * 根から葉までの決定木の深さを表す
  * 深ければ深いほど分岐数も増えるため説明力が上がる
  * 深すぎると意味のない分岐もできやすく過学習のリスクが上がる

* min_samples_leaf
  * 葉に属する最小サンプル数を表す
  * サンプルが少ないと信憑性の低い分岐である可能性がある

## パラメータの検証方法
* 未知のデータに対しても予測できる必要がある
* 学習データから仮の未知データを作って実現する

## データセットの分割例
1. 学習データと評価データに分ける
2. チューニングのためにモデル構築用データとモデル検証データをつくる
3. 分割した学習データの中で精度の良さそうなパラメータを見つける

* 学習データ
  * 構築データ
  * 検証データ
* 評価データ

## パラメータ検証の手順
1. 構築データ自体の精度を評価する
2. 検証データ自体の精度を評価する
3. 両方の乖離が小さく検証データの精度が良いパラメータを選ぶ

* 構築データはモデルに対してデータフィッティングをするほどデータの精度が上がる
* 検証データの場合、一定までは精度が上がるが途中から過学習が起こりデータの精度が下がっていく
* 過学習が発生する直前のポイント、両方のデータ精度の乖離が小さくなるパラメータを探していく

## 構築データと検証データの分割方法
### ホールドアウト法
#### 概要
* 方法が単純であり、データが大量に有れば欠点を補えるため有効な手法
* 学習データを単純に２分割する

#### 分割方法
* 片方をモデル構築データ、残りをモデル検証データとする
* 分割する割合は通例 __学習：検証＝7：3__
* どこで分割するかで検証精度が大きく変わりうるという欠点がある
  * 構築データが多い：検証が不十分になりパラメータの信憑性がなくなる
  * 構築データが少ない：学習が不十分になりどれだけチューニングしてもモデル自体の精度が良くならない

### クロスバリデーション法（K分割交差検証）
#### 概要
* ホールドアウト法の欠点を補った手法
* 計算が複雑で時間がかかる
* データにばらつきがあっても分割して平均を取るので過学習になりにくいパラメータを選択できる

#### 分割方法
* データをK個に分割し、検証をK回繰り返す
  * __K-1個__ をモデルデータとし、残り1個を検証データとする
  * 他の組み合わせでも同じことを行い、平均精度を元にパラメータを決定する

#### 例）K=3の場合
1. 学習データを3分割する
2. 分割したデータ（①②③）を以下3通りの組み合わせで、それぞれ構築データと検証データの精度を出す
    * ①構築データ　②構築データ　③検証データ
    * ①構築データ　②検証データ　③構築データ
    * ①検証データ　②構築データ　③構築データ
3. 平均をとり、構築データと検証データの精度とする