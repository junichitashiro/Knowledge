# パラメータチューニングの実践

ここでは[SIGNATEの練習問題データ](https://signate.jp/competitions/1/data)を使用している

## 作業の概要
* このケースでは __06-決定木モデルの作成__ で作成した決定木モデルのパラメータをチューニングする

## データの準備
* ライブラリのインポート
  ```python
  import pandas as pd
  import numpy as np
  from matplotlib import pyplot as plt
  %matplotlib inline

  from sklearn.tree import DecisionTreeClassifier as DT
  from sklearn.model_selection import cross_validate
  from sklearn.model_selection import GridSearchCV
  ```

* CSVデータの読み込み
  ```python
  train = pd.read_csv("train.csv")
  test = pd.read_csv("test.csv")
  sample = pd.read_csv("submit_sample.csv",header=None)
  ```

## 説明変数と目的変数の設定
* 学習データの説明変数を抽出する
* 目的変数y以外のカラムを説明変数に設定する
  ```python
  trainX = train.iloc[:,0:17]
  ```

* 学習データの目的変数を抽出する
  ```python
  y = train["y"]
  ```

* 評価データの説明変数を抽出する
* 全カラムを説明変数に設定する
  ```python
  testX = test.copy()
  ```

* 質的データをダミー変数化する
  ```python
  trainX = pd.get_dummies(trainX)
  testX = pd.get_dummies(testX)
  ```

## モデルの準備
* モデルを表す変数を用意する
* 何個も作る可能性があるため項番を付与した変数にする
* パラメータは一旦、前回と同じにする
  ```python
  clf1 = DT(max_depth=2,min_samples_leaf=500)
  ```

## クロスバリデーションでモデルの精度を確認する
* fit関数（説明変数、目的変数の順に指定）でモデルを作成する
* オプションの説明
  * cv：データ分割数（Kに相当）
  * scoring：評価尺度
  * n_jobs：並列処理をするかどうか（-1で全てのCPUコア数を使用）
  ```python
  cross_validate(clf1,trainX,y,cv=5,scoring="roc_auc",n_jobs=-1,return_train_score=True)
  ```

## パラメータを変えて再度実行する
  ```python
  clf2 = DT(max_depth=10,min_samples_leaf=500)

  cross_validate(clf2,trainX,y,cv=5,scoring="roc_auc",n_jobs=-1,return_train_score=True)
  ```

## グリッドサーチによるパラメータ探索
* 指定したパラメータ範囲の中で最適な精度を確認する方法
* 1つ1つパラメータを設定して精度を確かめる手間がない

## モデルの準備
* 新しく決定木モデルを表す変数を用意する
  ```python
  clf3 = DT()
  ```

* 探索するパラメータ範囲を表す変数を用意する
* ここではmax_pedpthを2から10まで探索する
  ```python
  parameters = {"max_depth":[2,3,4,5,6,7,8,9,10]}

  # rangeを使った書き方
  parameters = {"max_depth":list(range(2,11))}

  # 変数の内容を確認する
  parameters
  ```

## グリッドサーチとクロスバリデーションを組み合わせて最適なパラメータを探す
* グリッドサーチの結果を変数gcvに代入し、fit関数を使って探索を実行する
  ```python
  gcv = GridSearchCV(clf3,parameters,cv=5,scoring="roc_auc",n_jobs=-1,return_train_score=True)
  gcv.fit(trainX,y)
  ```

* 結果を表示する
  ```python
  gcv.cv_results_
  ```

* 重要な項目だけ取り出す
  ```python
  train_score = gcv.cv_results_["mean_train_score"]
  test_score = gcv.cv_results_["mean_test_score"]
  ```

## 取り出した項目を可視化する
* x軸をmax_depth、y軸をaucとしてグラフを描く
* このモデルではmax_depthの最小値を2に設定しているので調整する
  ```python
  # 青：モデル構築用データ | 橙：モデル検証用データ
  plt.plot(train_score)
  plt.plot(test_score)

  # x軸の0～9を2～10に調整する
  plt.xticks([0,1,2,3,4,5,6,7,8],[2,3,4,5,6,7,8,9,10])
  ```

* パラメータの最適値を表示する
* 検証用データの精度が高く、構築用データとの乖離が少ない箇所が該当する
  ```python
  gcv.best_params_
  ```

* 予測結果を変数に代入する
* gcvもpredict_proba関数を持っており、自動的に最適なパラメータを使ったモデルで予測される
  ```python
  pred = gcv.predict_proba(testX)

  # 1の確率のみを取り出して再度代入
  pred = pred[:,1]
  ```

## モデルの評価
* SIGNATEで評価する形式にデータを加工する
* sampleファイルのカラム[1]に、予測結果を代入する
  ```python
  sample[1] = pred
  ```

* sampleをCSVファイルに書き出す
  ```python
  sample.to_csv("submit2_bank.csv",index=None,header=None)
  ```

* 書き出したファイルを[SIGNATE](https://signate.jp/competitions/24/data)に投稿して評価を確認する
